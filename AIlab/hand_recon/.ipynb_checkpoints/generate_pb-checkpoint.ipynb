{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4ee4d82-55da-40e6-a10f-2add05b643f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x00000241B3EDBCA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('model',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x00000241B3EDBCA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('model',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "\n",
    "models.save_model(models.load_model('model/h5/model_2.h5'), 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5215231-de65-4e79-aee6-2964728c1e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "import numpy as np\n",
    "\n",
    "#path of the directory where you want to save your model\n",
    "frozen_out_path = 'Frozen'\n",
    "# name of the .pb file\n",
    "frozen_graph_filename = 'frozen_graph'\n",
    "\n",
    "# Convert Keras model to ConcreteFunction\n",
    "full_model = tf.function(lambda input: model(input))\n",
    "full_model = full_model.get_concrete_function(\n",
    "    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))\n",
    "# Get frozen ConcreteFunction\n",
    "frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "frozen_func.graph.as_graph_def()\n",
    "layers = [op.name for op in frozen_func.graph.get_operations()]\n",
    "print(\"-\" * 60)\n",
    "print(\"Frozen model layers: \")\n",
    "for layer in layers:\n",
    "    print(layer)\n",
    "print(\"-\" * 60)\n",
    "print(\"Frozen model inputs: \")\n",
    "print(frozen_func.inputs)\n",
    "print(\"Frozen model outputs: \")\n",
    "print(frozen_func.outputs)\n",
    "# Save frozen graph to disk\n",
    "tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
    "                  logdir=frozen_out_path,\n",
    "                  name=f\"{frozen_graph_filename}.pb\",\n",
    "                  as_text=False)\n",
    "# Save its text representation\n",
    "tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
    "                  logdir=frozen_out_path,\n",
    "                  name=f\"{frozen_graph_filename}.pbtxt\",\n",
    "                  as_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecf298c5-03a0-4209-b901-7c6dd0b444dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Frozen model layers: \n",
      "input_x\n",
      "keep_prob/input\n",
      "keep_prob\n",
      "Variable\n",
      "Variable/read\n",
      "Variable_1\n",
      "Variable_1/read\n",
      "Conv2D\n",
      "add\n",
      "Relu\n",
      "MaxPool\n",
      "Variable_2\n",
      "Variable_2/read\n",
      "Variable_3\n",
      "Variable_3/read\n",
      "Conv2D_1\n",
      "add_1\n",
      "Relu_1\n",
      "MaxPool_1\n",
      "Variable_4\n",
      "Variable_4/read\n",
      "Variable_5\n",
      "Variable_5/read\n",
      "Conv2D_2\n",
      "add_2\n",
      "Relu_2\n",
      "MaxPool_2\n",
      "Variable_6\n",
      "Variable_6/read\n",
      "Variable_7\n",
      "Variable_7/read\n",
      "Reshape/shape\n",
      "Reshape\n",
      "MatMul\n",
      "add_3\n",
      "Relu_3\n",
      "dropout/Shape\n",
      "dropout/random_uniform/min\n",
      "dropout/random_uniform/max\n",
      "dropout/random_uniform/RandomUniform\n",
      "dropout/random_uniform/sub\n",
      "dropout/random_uniform/mul\n",
      "dropout/random_uniform\n",
      "dropout/add\n",
      "dropout/Floor\n",
      "dropout/div\n",
      "dropout/mul\n",
      "Variable_8\n",
      "Variable_8/read\n",
      "Variable_9\n",
      "Variable_9/read\n",
      "MatMul_1\n",
      "outlayer\n",
      "probability\n",
      "predict/dimension\n",
      "predict\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"The name 'Placeholder:0' refers to a Tensor which does not exist. The operation, 'Placeholder', does not exist in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7112/2221835506.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Wrap frozen graph to ConcreteFunctions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m frozen_func = wrap_frozen_graph(graph_def=graph_def,\n\u001b[0m\u001b[0;32m     28\u001b[0m                                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Placeholder:0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                                 \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss:0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7112/2221835506.py\u001b[0m in \u001b[0;36mwrap_frozen_graph\u001b[1;34m(graph_def, inputs, outputs, print_graph)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     return wrapped_import.prune(\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimport_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         tf.nest.map_structure(import_graph.as_graph_element, outputs))\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 914\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 914\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3973\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3974\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3975\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3976\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   4012\u001b[0m           \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes_by_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mop_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4013\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4014\u001b[1;33m           raise KeyError(\"The name %s refers to a Tensor which does not \"\n\u001b[0m\u001b[0;32m   4015\u001b[0m                          \u001b[1;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4016\u001b[0m                          \"graph.\" % (repr(name), repr(op_name)))\n",
      "\u001b[1;31mKeyError\u001b[0m: \"The name 'Placeholder:0' refers to a Tensor which does not exist. The operation, 'Placeholder', does not exist in the graph.\""
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def wrap_frozen_graph(graph_def, inputs, outputs, print_graph=False):\n",
    "    def _imports_graph_def():\n",
    "        tf.compat.v1.import_graph_def(graph_def, name=\"\")\n",
    "\n",
    "    wrapped_import = tf.compat.v1.wrap_function(_imports_graph_def, [])\n",
    "    import_graph = wrapped_import.graph\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Frozen model layers: \")\n",
    "    layers = [op.name for op in import_graph.get_operations()]\n",
    "    if print_graph == True:\n",
    "        for layer in layers:\n",
    "            print(layer)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    return wrapped_import.prune(\n",
    "        tf.nest.map_structure(import_graph.as_graph_element, inputs),\n",
    "        tf.nest.map_structure(import_graph.as_graph_element, outputs))\n",
    "\n",
    "with tf.io.gfile.GFile(\"model/digital_gesture500_200_c3.pb\", \"rb\") as f:\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    loaded = graph_def.ParseFromString(f.read())\n",
    "\n",
    "# Wrap frozen graph to ConcreteFunctions\n",
    "frozen_func = wrap_frozen_graph(graph_def=graph_def,\n",
    "                                inputs=[\"input_x:0\"],\n",
    "                                outputs=[\"predict:0\"],\n",
    "                                print_graph=True)\n",
    "print(\"-\" * 50)\n",
    "print(\"Frozen model inputs: \")\n",
    "print(frozen_func.inputs)\n",
    "print(\"Frozen model outputs: \")\n",
    "print(frozen_func.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b7dbc68-a9fe-48bc-81cc-0851b8cc028e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Frozen model layers: \n",
      "x\n",
      "sequential_1/conv2d_6/Conv2D/ReadVariableOp/resource\n",
      "sequential_1/conv2d_6/Conv2D/ReadVariableOp\n",
      "sequential_1/conv2d_6/Conv2D\n",
      "sequential_1/conv2d_6/BiasAdd/ReadVariableOp/resource\n",
      "sequential_1/conv2d_6/BiasAdd/ReadVariableOp\n",
      "sequential_1/conv2d_6/BiasAdd\n",
      "sequential_1/conv2d_6/Relu\n",
      "sequential_1/conv2d_7/Conv2D/ReadVariableOp/resource\n",
      "sequential_1/conv2d_7/Conv2D/ReadVariableOp\n",
      "sequential_1/conv2d_7/Conv2D\n",
      "sequential_1/conv2d_7/BiasAdd/ReadVariableOp/resource\n",
      "sequential_1/conv2d_7/BiasAdd/ReadVariableOp\n",
      "sequential_1/conv2d_7/BiasAdd\n",
      "sequential_1/conv2d_7/Relu\n",
      "sequential_1/max_pooling2d_3/MaxPool\n",
      "sequential_1/dropout_6/Identity\n",
      "sequential_1/conv2d_8/Conv2D/ReadVariableOp/resource\n",
      "sequential_1/conv2d_8/Conv2D/ReadVariableOp\n",
      "sequential_1/conv2d_8/Conv2D\n",
      "sequential_1/conv2d_8/BiasAdd/ReadVariableOp/resource\n",
      "sequential_1/conv2d_8/BiasAdd/ReadVariableOp\n",
      "sequential_1/conv2d_8/BiasAdd\n",
      "sequential_1/conv2d_8/Relu\n",
      "sequential_1/conv2d_9/Conv2D/ReadVariableOp/resource\n",
      "sequential_1/conv2d_9/Conv2D/ReadVariableOp\n",
      "sequential_1/conv2d_9/Conv2D\n",
      "sequential_1/conv2d_9/BiasAdd/ReadVariableOp/resource\n",
      "sequential_1/conv2d_9/BiasAdd/ReadVariableOp\n",
      "sequential_1/conv2d_9/BiasAdd\n",
      "sequential_1/conv2d_9/Relu\n",
      "sequential_1/max_pooling2d_4/MaxPool\n",
      "sequential_1/dropout_7/Identity\n",
      "sequential_1/conv2d_10/Conv2D/ReadVariableOp/resource\n",
      "sequential_1/conv2d_10/Conv2D/ReadVariableOp\n",
      "sequential_1/conv2d_10/Conv2D\n",
      "sequential_1/conv2d_10/BiasAdd/ReadVariableOp/resource\n",
      "sequential_1/conv2d_10/BiasAdd/ReadVariableOp\n",
      "sequential_1/conv2d_10/BiasAdd\n",
      "sequential_1/conv2d_10/Relu\n",
      "sequential_1/conv2d_11/Conv2D/ReadVariableOp/resource\n",
      "sequential_1/conv2d_11/Conv2D/ReadVariableOp\n",
      "sequential_1/conv2d_11/Conv2D\n",
      "sequential_1/conv2d_11/BiasAdd/ReadVariableOp/resource\n",
      "sequential_1/conv2d_11/BiasAdd/ReadVariableOp\n",
      "sequential_1/conv2d_11/BiasAdd\n",
      "sequential_1/conv2d_11/Relu\n",
      "sequential_1/max_pooling2d_5/MaxPool\n",
      "sequential_1/dropout_8/Identity\n",
      "sequential_1/flatten_1/Const\n",
      "sequential_1/flatten_1/Reshape\n",
      "sequential_1/dense_4/MatMul/ReadVariableOp/resource\n",
      "sequential_1/dense_4/MatMul/ReadVariableOp\n",
      "sequential_1/dense_4/MatMul\n",
      "sequential_1/dense_4/BiasAdd/ReadVariableOp/resource\n",
      "sequential_1/dense_4/BiasAdd/ReadVariableOp\n",
      "sequential_1/dense_4/BiasAdd\n",
      "sequential_1/dense_4/Relu\n",
      "sequential_1/dropout_9/Identity\n",
      "sequential_1/dense_5/MatMul/ReadVariableOp/resource\n",
      "sequential_1/dense_5/MatMul/ReadVariableOp\n",
      "sequential_1/dense_5/MatMul\n",
      "sequential_1/dense_5/BiasAdd/ReadVariableOp/resource\n",
      "sequential_1/dense_5/BiasAdd/ReadVariableOp\n",
      "sequential_1/dense_5/BiasAdd\n",
      "sequential_1/dense_5/Relu\n",
      "sequential_1/dropout_10/Identity\n",
      "sequential_1/dense_6/MatMul/ReadVariableOp/resource\n",
      "sequential_1/dense_6/MatMul/ReadVariableOp\n",
      "sequential_1/dense_6/MatMul\n",
      "sequential_1/dense_6/BiasAdd/ReadVariableOp/resource\n",
      "sequential_1/dense_6/BiasAdd/ReadVariableOp\n",
      "sequential_1/dense_6/BiasAdd\n",
      "sequential_1/dense_6/Relu\n",
      "sequential_1/dropout_11/Identity\n",
      "sequential_1/dense_7/MatMul/ReadVariableOp/resource\n",
      "sequential_1/dense_7/MatMul/ReadVariableOp\n",
      "sequential_1/dense_7/MatMul\n",
      "sequential_1/dense_7/BiasAdd/ReadVariableOp/resource\n",
      "sequential_1/dense_7/BiasAdd/ReadVariableOp\n",
      "sequential_1/dense_7/BiasAdd\n",
      "sequential_1/dense_7/Sigmoid\n",
      "NoOp\n",
      "Identity\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Frozen model inputs: \n",
      "[<tf.Tensor 'x:0' shape=(None, 50, 50, 3) dtype=float32>]\n",
      "Frozen model outputs: \n",
      "[<tf.Tensor 'Identity:0' shape=(None, 31) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def wrap_frozen_graph(graph_def, inputs, outputs, print_graph=False):\n",
    "    def _imports_graph_def():\n",
    "        tf.compat.v1.import_graph_def(graph_def, name=\"\")\n",
    "\n",
    "    wrapped_import = tf.compat.v1.wrap_function(_imports_graph_def, [])\n",
    "    import_graph = wrapped_import.graph\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Frozen model layers: \")\n",
    "    layers = [op.name for op in import_graph.get_operations()]\n",
    "    if print_graph == True:\n",
    "        for layer in layers:\n",
    "            print(layer)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    return wrapped_import.prune(\n",
    "        tf.nest.map_structure(import_graph.as_graph_element, inputs),\n",
    "        tf.nest.map_structure(import_graph.as_graph_element, outputs))\n",
    "\n",
    "with tf.io.gfile.GFile(\"Frozen/frozen_graph.pb\", \"rb\") as f:\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    loaded = graph_def.ParseFromString(f.read())\n",
    "\n",
    "# Wrap frozen graph to ConcreteFunctions\n",
    "frozen_func = wrap_frozen_graph(graph_def=graph_def,\n",
    "                                inputs=[\"x:0\"],\n",
    "                                outputs=[\"Identity:0\"],\n",
    "                                print_graph=True)\n",
    "print(\"-\" * 50)\n",
    "print(\"Frozen model inputs: \")\n",
    "print(frozen_func.inputs)\n",
    "print(\"Frozen model outputs: \")\n",
    "print(frozen_func.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8877ed53-d8fd-43b8-8cb8-774346044ef6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_UserObject' object has no attribute 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3436/2808026383.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mfull_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m full_model = full_model.get_concrete_function(\n\u001b[1;32m---> 12\u001b[1;33m     x=tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Get frozen ConcreteFunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_UserObject' object has no attribute 'inputs'"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model = keras.models.load_model('model/h5/model_2.h5')\n",
    "\n",
    "# Convert Keras model to ConcreteFunction\n",
    "full_model = tf.function(lambda x: model(x))\n",
    "full_model = full_model.get_concrete_function(\n",
    "    x=tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))\n",
    "\n",
    "# Get frozen ConcreteFunction\n",
    "frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "frozen_func.graph.as_graph_def()\n",
    "\n",
    "# inspect the layers operations inside your frozen graph definition and see the name of its input and output tensors\n",
    "layers = [op.name for op in frozen_func.graph.get_operations()]\n",
    "print(\"-\" * 50)\n",
    "print(\"Frozen model layers: \")\n",
    "for layer in layers:\n",
    "    print(layer)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"Frozen model inputs: \")\n",
    "print(frozen_func.inputs)\n",
    "print(\"Frozen model outputs: \")\n",
    "print(frozen_func.outputs)\n",
    "\n",
    "# Save frozen graph from frozen ConcreteFunction to hard drive\n",
    "# serialize the frozen graph and its text representation to disk.\n",
    "tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
    "                  logdir=\"Frozen\",\n",
    "                  name=\"simple_frozen_graph.pb\",\n",
    "                  as_text=False)\n",
    "\n",
    "#Optional\n",
    "tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
    "                  logdir=\"Frozen\",\n",
    "                  name=\"simple_frozen_graph.pbtxt\",\n",
    "                as_text=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d2e63b-1e7b-4690-a2ea-0f8f95415318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
